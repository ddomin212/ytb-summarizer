{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7b1308f-0662-4686-a8f4-2e89d996968f","_uuid":"9c17d049-9b37-4ad3-9f56-ecbb8843d42b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","import json\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","FILE_PATHS = []\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        FILE_PATHS.append(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install bardapi"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ff011c1-287b-49de-b0c2-af711fb42f07","_uuid":"c6cefd93-8fe5-4c5f-9e9f-2b2ea4bd7064","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["!pip install youtube-transcript-api faiss-cpu langchain sentence-transformers gradio-client"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CHUNK_SIZE = 1000\n","CHUNK_OVERLAP = 50"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import textwrap\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.document_loaders import YoutubeLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.vectorstores import FAISS\n","from langchain.chains import LLMChain\n","from langchain.chains.summarize import load_summarize_chain\n","from langchain.prompts.chat import (\n","    ChatPromptTemplate,\n","    SystemMessagePromptTemplate,\n","    HumanMessagePromptTemplate,\n",")\n","from langchain.docstore.document import Document"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["f = open(FILE_PATHS[0])\n","obj = json.load(f)\n","f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","from typing import Any, List, Mapping, Optional\n","from bardapi import BardCookies\n","from langchain.callbacks.manager import CallbackManagerForLLMRun\n","from langchain.llms.base import LLM\n","\n","cookie_dict = {\n","    \"__Secure-1PSID\": obj[\"_1PSID\"],\n","    \"__Secure-1PSIDTS\": obj[\"_1PSIDTS\"],\n","    \"__Secure-1PSIDCC\": obj[\"_1PSIDCC\"],\n","    # Any cookie values you want to pass session object.\n","}\n","\n","class GPTv1(LLM):\n","    @property\n","    def _llm_type(self) -> str:\n","        return \"custom\"\n","\n","    def _call(\n","        self,\n","        prompt: str,\n","        stop: Optional[List[str]] = None,\n","        run_manager: Optional[CallbackManagerForLLMRun] = None,\n","    ) -> str:\n","        bard = BardCookies(cookie_dict=cookie_dict)\n","        response = bard.get_answer(prompt)\n","        return response['content']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from gradio_client import Client\n","def get_whisper_transcription(video_url):\n","    client = Client(\"https://sanchit-gandhi-whisper-jax.hf.space/\")\n","    result = client.predict(\n","        video_url,  # str  in 'YouTube URL' Textbox component\n","        \"transcribe\",  # str  in 'Task' Radio component\n","        False,  # bool  in 'Return timestamps' Checkbox component\n","        api_name=\"/predict_2\",\n","    )\n","    return result[1]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def create_db_from_youtube_video_url(video_url):\n","    model_kwargs = {'device': 'gpu'}\n","    embeddings = HuggingFaceEmbeddings(\n","        model_name=\"BAAI/bge-large-en-v1.5\"\n","    )\n","    loader = YoutubeLoader.from_youtube_url(video_url, language=[obj[\"output_lang_code\"].lower(), obj[\"input_lang_code\"].lower()], translation=obj[\"output_lang_code\"])\n","    transcript = loader.load()\n","\n","    if len(transcript) == 0:\n","        transcript = get_whisper_transcription(video_url)\n","        text_splitter = RecursiveCharacterTextSplitter(\n","            chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP\n","        )\n","        texts = text_splitter.split_text(transcript)\n","        docs = [Document(page_content=t) for t in texts]\n","    else:\n","        text_splitter = RecursiveCharacterTextSplitter(\n","            chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP\n","        )\n","        docs = text_splitter.split_documents(transcript)\n","\n","    db = FAISS.from_documents(docs, embeddings)\n","    return db"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_response_from_query(db, query, k=4):\n","    \"\"\"\n","    gpt-3.5-turbo can handle up to 4097 tokens. Setting the chunksize to 1000 and k to 4 maximizes\n","    the number of tokens to analyze.\n","    \"\"\"\n","\n","    docs = db.similarity_search(query, k=k)\n","    docs_page_content = \" \".join([d.page_content for d in docs])\n","    \n","    chat = GPTv1()\n","    \n","    # Template to use for the system message prompt\n","    template = f\"\"\"\n","        You are a helpful assistant that that can answer questions about youtube videos \n","        based on the video's transcript: {'{docs}'}\n","\n","        The language of the transcript is for you to infer.\n","        \n","        Only use the factual information from the transcript to answer the question.\n","        \n","        If you feel like you don't have enough information to answer the question, say \"I don't know\".\n","        \n","        Your answers should be verbose and detailed, and also, in this language: {obj[\"output_lang\"]}.\n","\n","        ANSWER IN {obj[\"output_lang\"]}:\n","        \"\"\"\n","\n","    system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n","\n","    # Human question prompt\n","    human_template = \"Answer the following question: {question}\"\n","    human_message_prompt = HumanMessagePromptTemplate.from_template(\n","        human_template\n","    )\n","\n","    chat_prompt = ChatPromptTemplate.from_messages(\n","        [system_message_prompt, human_message_prompt]\n","    )\n","\n","    chain = LLMChain(llm=chat, prompt=chat_prompt)\n","\n","    response = chain.run(question=query, docs=docs_page_content)\n","    response = response.replace(\"\\n\", \"\")\n","    return response"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain.prompts import PromptTemplate\n","from langchain.document_transformers import (\n","    LongContextReorder,\n",")\n","def summarize_video(link):\n","\n","    loader = YoutubeLoader.from_youtube_url(link, language=[obj[\"output_lang_code\"].lower(), obj[\"input_lang_code\"].lower()], translation=obj[\"output_lang_code\"])\n","    transcript = loader.load()\n","\n","    if len(transcript) == 0:\n","        transcript = get_whisper_transcription(link)\n","        text_file = open(\"test.txt\", \"w\")\n","        n = text_file.write(transcript)\n","        text_file.close()\n","        text_splitter = RecursiveCharacterTextSplitter(\n","            chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP\n","        )\n","        texts = text_splitter.split_text(transcript)\n","        docs = [Document(page_content=t) for t in texts]\n","        reordering = LongContextReorder()\n","        docs = reordering.transform_documents(docs)\n","    else:\n","        text_splitter = RecursiveCharacterTextSplitter(\n","            chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP\n","        )\n","        reordering = LongContextReorder()\n","        docs = reordering.transform_documents(docs)\n","        docs = text_splitter.split_documents(transcript)\n","\n","    prompt_template = \"\"\"You are given a transcript of a youtube video. The language of the transcript is for you to infer.\n","    Your job is to summarize the overall point of the video in the same langugage, while\n","    highlightning any actionable points the video has to offer. Summarize the following:\n","\n","\n","    {text}\n","\n","\n","    CONCISE SUMMARY IN \"\"\" + obj[\"output_lang\"] + \":\"\n","\n","    gptlm = GPTv1()\n","    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n","    # Add map_prompt and combine_prompt to the chain for custom summarization\n","    chain = load_summarize_chain(gptlm, chain_type=\"map_reduce\", map_prompt=PROMPT)\n","    print(chain.llm_chain.prompt.template)\n","    print(chain.combine_document_chain.llm_chain.prompt.template)\n","\n","    output_summary = chain.run(docs)\n","    response = textwrap.fill(\n","        output_summary,\n","        width=100,\n","        break_long_words=False,\n","        replace_whitespace=False,\n","    )\n","    return response"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if obj[\"type\"] == \"chat\":\n","    db = create_db_from_youtube_video_url(obj[\"link\"])\n","    response = get_response_from_query(db, obj[\"query\"])\n","else:\n","    response = summarize_video(obj[\"link\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["text_file = open(\"out.txt\", \"w\")\n","n = text_file.write(response)\n","text_file.close()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
