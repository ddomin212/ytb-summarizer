{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-06-14T11:39:46.995941Z","iopub.status.busy":"2023-06-14T11:39:46.995564Z","iopub.status.idle":"2023-06-14T11:39:47.003618Z","shell.execute_reply":"2023-06-14T11:39:47.002732Z","shell.execute_reply.started":"2023-06-14T11:39:46.995914Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T11:39:47.006143Z","iopub.status.busy":"2023-06-14T11:39:47.005232Z","iopub.status.idle":"2023-06-14T11:39:58.520380Z","shell.execute_reply":"2023-06-14T11:39:58.519021Z","shell.execute_reply.started":"2023-06-14T11:39:47.006112Z"},"trusted":true},"outputs":[],"source":["!pip install faiss-cpu langchain sentence-transformers "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T11:39:58.522794Z","iopub.status.busy":"2023-06-14T11:39:58.522478Z","iopub.status.idle":"2023-06-14T11:40:09.934488Z","shell.execute_reply":"2023-06-14T11:40:09.932961Z","shell.execute_reply.started":"2023-06-14T11:39:58.522763Z"},"trusted":true},"outputs":[],"source":["!pip install revChatGPT --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T11:40:09.985128Z","iopub.status.busy":"2023-06-14T11:40:09.984497Z","iopub.status.idle":"2023-06-14T11:40:09.995999Z","shell.execute_reply":"2023-06-14T11:40:09.994928Z","shell.execute_reply.started":"2023-06-14T11:40:09.985092Z"},"trusted":true},"outputs":[],"source":["import json\n","f = open('/kaggle/input/cocaster-data/data.json')\n","obj = json.load(f)\n","f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T11:40:09.966127Z","iopub.status.busy":"2023-06-14T11:40:09.965442Z","iopub.status.idle":"2023-06-14T11:40:09.981995Z","shell.execute_reply":"2023-06-14T11:40:09.980957Z","shell.execute_reply.started":"2023-06-14T11:40:09.966091Z"},"trusted":true},"outputs":[],"source":["from revChatGPT.V1 import Chatbot\n","from langchain.callbacks.manager import CallbackManagerForLLMRun\n","from langchain.llms.base import LLM\n","from typing import Any, List, Mapping, Optional, Dict\n","\n","class GPTv1(LLM):\n","    chatbot = Chatbot(\n","        config={\n","            \"access_token\": obj['token']\n","        }\n","    )\n","\n","    @property\n","    def _llm_type(self) -> str:\n","        return \"custom\"\n","\n","    def _call(\n","        self,\n","        prompt: str,\n","        stop: Optional[List[str]] = None,\n","        run_manager: Optional[CallbackManagerForLLMRun] = None,\n","    ) -> str:\n","        print(prompt)\n","        response = \"\"\n","        for data in self.chatbot.ask(prompt):\n","            response = data[\"message\"]\n","        print(\"actually using revChatGPT\")\n","        return response"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T11:40:09.998361Z","iopub.status.busy":"2023-06-14T11:40:09.997724Z","iopub.status.idle":"2023-06-14T11:40:10.007606Z","shell.execute_reply":"2023-06-14T11:40:10.006666Z","shell.execute_reply.started":"2023-06-14T11:40:09.998305Z"},"trusted":true},"outputs":[],"source":["import re\n","from datetime import datetime\n","\n","def clean_text(text: str):\n","    \"\"\"\n","    Cleans a block of text by removing newlines, extra whitespace, and HTML tags.\n","\n","    Args:\n","        text (str): The text to clean.\n","\n","    Returns:\n","        str: The cleaned text.\n","    \"\"\"\n","    pattern = re.compile(r\"&#\\d{1,2};|<.*?>|&quot;|&amp;|&gt;|&lt;\")\n","    return pattern.sub(\"\", text)\n","\n","def convert_date_unix(string_date: str):\n","    \"\"\"\n","    Converts a string date in the format \"%Y-%m-%dT%H:%M:%SZ\" to a Unix timestamp.\n","\n","    Args:\n","        string_date (str): The string date to convert.\n","\n","    Returns:\n","        int: The Unix timestamp.\n","    \"\"\"\n","    date_obj = datetime.strptime(string_date, \"%Y-%m-%dT%H:%M:%SZ\")\n","    return int(date_obj.timestamp())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T11:40:10.012843Z","iopub.status.busy":"2023-06-14T11:40:10.012217Z","iopub.status.idle":"2023-06-14T11:40:10.040064Z","shell.execute_reply":"2023-06-14T11:40:10.039024Z","shell.execute_reply.started":"2023-06-14T11:40:10.012809Z"},"trusted":true},"outputs":[],"source":["from googleapiclient.discovery import build, Resource\n","\n","\n","all_comments: List[Dict[str, Any]] = []\n","\n","\n","def get_comments(video_id: str):\n","    \"\"\"\n","    Given a YouTube video ID, retrieves the top-level comments for the video and returns\n","    them along with the video's title, description, and publish date.\n","\n","    Args:\n","        video_id (str): The ID of the YouTube video to scrape.\n","\n","    Returns:\n","        Tuple[List[Dict[str, Any]], Tuple[str, str, str]]: A tuple containing a list of\n","        dictionaries representing the top-level comments for the video, and a tuple\n","        containing the video's title, description, and publish date.\n","    \"\"\"\n","\n","    gapi_key = obj['gapi_key']\n","\n","    # Create a youtube resource object\n","    youtube = build(\"youtube\", \"v3\", developerKey=gapi_key)\n","    \n","    video_id = video_id.split('?v=')[1]\n","    get_comments_helper(youtube, video_id, \"\")\n","\n","\n","def get_comments_helper(youtube: Resource, video_id: str, token: str = \"\"):\n","    \"\"\"\n","    Recursive function that retrieves the top-level comments for a given YouTube video.\n","\n","    Args:\n","        youtube (Any): The YouTube resource object.\n","        video_id (str): The ID of the YouTube video to scrape.\n","        token (str, optional): The token to use when retrieving comments. Defaults to \"\".\n","    \"\"\"\n","\n","    global all_comments\n","    total_reply_count = 0\n","    token_reply = None\n","\n","    if len(token.strip()) == 0:\n","        all_comments = []\n","\n","    if token == \"\":\n","        video_response = (\n","            youtube.commentThreads()\n","            .list(part=\"snippet\", maxResults=100, videoId=video_id, order=\"relevance\")\n","            .execute()\n","        )\n","    else:\n","        video_response = (\n","            youtube.commentThreads()\n","            .list(\n","                part=\"snippet\",\n","                maxResults=100,\n","                videoId=video_id,\n","                order=\"relevance\",\n","                pageToken=token,\n","            )\n","            .execute()\n","        )\n","\n","    # Loop comments from the video:\n","    for idx, item in enumerate(video_response[\"items\"]):\n","        # Append coments:\n","        cleaned_text_thread = clean_text(\n","            item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n","        )\n","        if len(cleaned_text_thread.strip()) > 10:\n","            comment_thread = {\n","                \"comment_text\": cleaned_text_thread,\n","                \"comment_author\": item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\n","                    \"authorDisplayName\"\n","                ],\n","                \"comment_author_url\": item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\n","                    \"authorChannelUrl\"\n","                ],\n","                \"comment_author_image\": item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\n","                    \"authorProfileImageUrl\"\n","                ],\n","                \"comment_published_at\": item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\n","                    \"updatedAt\"\n","                ],\n","                \"comment_published_at_unix\": convert_date_unix(\n","                    item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"updatedAt\"]\n","                ),\n","                \"comment_like_count\": item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\n","                    \"likeCount\"\n","                ],\n","                \"comment_id\": item[\"snippet\"][\"topLevelComment\"][\"id\"],\n","                \"comment_parent_id\": item[\"snippet\"][\"topLevelComment\"][\"id\"],\n","            }\n","            all_comments.append(comment_thread)\n","\n","        # Get total reply count:\n","        total_reply_count = item[\"snippet\"][\"totalReplyCount\"]\n","\n","        # If the comment has replies, get them:\n","        if total_reply_count > 0:\n","            # Get replies - first batch:\n","            replies_response = (\n","                youtube.comments()\n","                .list(part=\"snippet\", maxResults=100, parentId=item[\"id\"])\n","                .execute()\n","            )\n","            for reply in replies_response[\"items\"]:\n","                # Append the replies to the main array:\n","                cleaned_text = clean_text(reply[\"snippet\"][\"textDisplay\"])\n","                if len(cleaned_text.strip()) > 10:\n","                    comment = {\n","                        \"comment_text\": cleaned_text,\n","                        \"comment_author\": reply[\"snippet\"][\"authorDisplayName\"],\n","                        \"comment_author_url\": reply[\"snippet\"][\"authorChannelUrl\"],\n","                        \"comment_author_image\": reply[\"snippet\"][\n","                            \"authorProfileImageUrl\"\n","                        ],\n","                        \"comment_published_at\": reply[\"snippet\"][\"updatedAt\"],\n","                        \"comment_published_at_unix\": convert_date_unix(\n","                            reply[\"snippet\"][\"updatedAt\"]\n","                        ),\n","                        \"comment_like_count\": reply[\"snippet\"][\"likeCount\"],\n","                        \"comment_id\": reply[\"id\"],\n","                        \"comment_parent_id\": item[\"id\"],\n","                    }\n","                    all_comments.append(comment)\n","\n","            # If the reply has a token for get more replies, loop those replies\n","            # and add those replies to the main array:\n","            while \"nextPageToken\" in replies_response:\n","                token_reply = replies_response[\"nextPageToken\"]\n","                replies_response = (\n","                    youtube.comments()\n","                    .list(\n","                        part=\"snippet\",\n","                        maxResults=100,\n","                        parentId=item[\"id\"],\n","                        pageToken=token_reply,\n","                    )\n","                    .execute()\n","                )\n","                for reply in replies_response[\"items\"]:\n","                    cleaned_text = clean_text(reply[\"snippet\"][\"textDisplay\"])\n","                    if len(cleaned_text.strip()) > 10:\n","                        comment_more = {\n","                            \"comment_text\": cleaned_text,\n","                            \"comment_author\": reply[\"snippet\"][\"authorDisplayName\"],\n","                            \"comment_author_url\": reply[\"snippet\"][\"authorChannelUrl\"],\n","                            \"comment_author_image\": reply[\"snippet\"][\n","                                \"authorProfileImageUrl\"\n","                            ],\n","                            \"comment_published_at\": reply[\"snippet\"][\"updatedAt\"],\n","                            \"comment_published_at_unix\": convert_date_unix(\n","                                reply[\"snippet\"][\"updatedAt\"]\n","                            ),\n","                            \"comment_like_count\": reply[\"snippet\"][\"likeCount\"],\n","                            \"comment_id\": reply[\"id\"],\n","                            \"comment_parent_id\": item[\"id\"],\n","                        }\n","                        all_comments.append(comment_more)\n","\n","    if \"nextPageToken\" in video_response:\n","        return get_comments_helper(youtube, video_id, video_response[\"nextPageToken\"])\n","    # Remove empty elements added to the list \"due to the return in both functions\":\n","    all_comments = [x for x in all_comments if len(x) > 0]\n","    print(\"Fin\")\n","    return []\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T11:40:10.041874Z","iopub.status.busy":"2023-06-14T11:40:10.041459Z","iopub.status.idle":"2023-06-14T11:40:30.166020Z","shell.execute_reply":"2023-06-14T11:40:30.164503Z","shell.execute_reply.started":"2023-06-14T11:40:10.041837Z"},"trusted":true},"outputs":[],"source":["comments = get_comments(obj['link'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T11:40:30.169396Z","iopub.status.busy":"2023-06-14T11:40:30.169071Z","iopub.status.idle":"2023-06-14T11:40:30.175484Z","shell.execute_reply":"2023-06-14T11:40:30.174532Z","shell.execute_reply.started":"2023-06-14T11:40:30.169369Z"},"trusted":true},"outputs":[],"source":["corpus = \"\"\n","count_comments = 0\n","for i in all_comments:\n","    corpus += i['comment_text'] + \"'\\n'\"\n","    count_comments += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T11:40:30.178714Z","iopub.status.busy":"2023-06-14T11:40:30.177689Z","iopub.status.idle":"2023-06-14T11:40:30.196202Z","shell.execute_reply":"2023-06-14T11:40:30.195281Z","shell.execute_reply.started":"2023-06-14T11:40:30.178670Z"},"trusted":true},"outputs":[],"source":["from langchain.docstore.document import Document\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.vectorstores import FAISS\n","from langchain.chains import LLMChain\n","from langchain.chains.summarize import load_summarize_chain\n","from langchain.prompts.chat import (\n","    ChatPromptTemplate,\n","    SystemMessagePromptTemplate,\n","    HumanMessagePromptTemplate,\n",")\n","from langchain.prompts import PromptTemplate\n","\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n","texts = text_splitter.split_text(corpus)\n","docs = [Document(page_content=t) for t in texts]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T11:40:30.200130Z","iopub.status.busy":"2023-06-14T11:40:30.199348Z","iopub.status.idle":"2023-06-14T11:40:30.208893Z","shell.execute_reply":"2023-06-14T11:40:30.207950Z","shell.execute_reply.started":"2023-06-14T11:40:30.200104Z"},"trusted":true},"outputs":[],"source":["def summarize_comments(docs):\n","    \n","    print(len(docs))\n","    #gptlm = HuggingFacePipeline.from_model_id(model_id=\"tiiuae/falcon-7b-instruct\", task=\"text-generation\", model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 500})\n","    gptlm = GPTv1()\n","    \n","    prompt_template = \"\"\"You are given a string of youtube comments, delimited by '\\n' character. Your job is to summarize the overall sentiment of these comments, while\n","    highlightning any constructive criticism that any of these comments might have. Summarize the following:\n","\n","\n","    {text}\n","\n","\n","    CONCISE SUMMARY:\"\"\"\n","    \n","    combine_template = \"\"\"You are given a sentiments for batches comments of a youtube video, along with any constructive critique they might contain.\n","    Summarize the sentiment for all batches in just a few sentences. Especially highlight any critique mentioned in a numbered list format, along\n","    with an actionable step that the creator can take to fix it.\n","    Summarize the following:\n","\n","\n","    {text}\n","\n","\n","    CONCISE SUMMARY:\"\"\"\n","    \n","    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n","    COMBINE = PromptTemplate(template=combine_template, input_variables=[\"text\"])\n","    chain = load_summarize_chain(gptlm, chain_type=\"map_reduce\", map_prompt=PROMPT, combine_prompt=COMBINE)\n","    print(chain.llm_chain.prompt.template)\n","    print(chain.combine_document_chain.llm_chain.prompt.template)\n","\n","    output_summary = chain.run(docs)\n","    return output_summary"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T11:42:10.941973Z","iopub.status.busy":"2023-06-14T11:42:10.941336Z","iopub.status.idle":"2023-06-14T11:42:10.950980Z","shell.execute_reply":"2023-06-14T11:42:10.950043Z","shell.execute_reply.started":"2023-06-14T11:42:10.941940Z"},"trusted":true},"outputs":[],"source":["def create_db_from_comments(docs):\n","    model_kwargs = {'device': 'gpu'}\n","    embeddings = HuggingFaceEmbeddings(\n","        model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n","    )\n","    db = FAISS.from_documents(docs, embeddings)\n","    return db"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T11:42:10.952786Z","iopub.status.busy":"2023-06-14T11:42:10.952221Z","iopub.status.idle":"2023-06-14T11:42:10.962648Z","shell.execute_reply":"2023-06-14T11:42:10.961731Z","shell.execute_reply.started":"2023-06-14T11:42:10.952751Z"},"trusted":true},"outputs":[],"source":["def get_response_from_query(db, query, k=2):\n","    \"\"\"\n","    gpt-3.5-turbo can handle up to 4097 tokens. Setting the chunksize to 1000 and k to 4 maximizes\n","    the number of tokens to analyze.\n","    \"\"\"\n","\n","    docs = db.similarity_search(query, k=k)\n","    docs_page_content = \" \".join([d.page_content for d in docs])\n","    \n","    chat = GPTv1()\n","    \n","    # Template to use for the system message prompt\n","    template = \"\"\"\n","        You are a helpful assistant that that can extract a comment base on the main topic: {docs}\n","        \n","        Only use information from the comments to answer the question.\n","        \n","        If you feel like you don't have enough information to answer the question, say \"I don't know\".\n","        \n","        Your answers should be verbose and detailed.\n","        \"\"\"\n","\n","    system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n","\n","    # Human question prompt\n","    human_template = \"Answer the following question: {question}\"\n","    human_message_prompt = HumanMessagePromptTemplate.from_template(\n","        human_template\n","    )\n","\n","    chat_prompt = ChatPromptTemplate.from_messages(\n","        [system_message_prompt, human_message_prompt]\n","    )\n","\n","    chain = LLMChain(llm=chat, prompt=chat_prompt)\n","\n","    response = chain.run(question=query, docs=docs_page_content)\n","    return response"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T11:42:10.964651Z","iopub.status.busy":"2023-06-14T11:42:10.964309Z","iopub.status.idle":"2023-06-14T11:42:54.090348Z","shell.execute_reply":"2023-06-14T11:42:54.089289Z","shell.execute_reply.started":"2023-06-14T11:42:10.964621Z"},"trusted":true},"outputs":[],"source":["if obj[\"type\"] == \"chat\":\n","    db = create_db_from_comments(docs)\n","    response = get_response_from_query(db, obj[\"query\"])\n","else:\n","    response = summarize_comments(docs)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T11:42:54.092759Z","iopub.status.busy":"2023-06-14T11:42:54.092057Z","iopub.status.idle":"2023-06-14T11:42:54.097770Z","shell.execute_reply":"2023-06-14T11:42:54.096881Z","shell.execute_reply.started":"2023-06-14T11:42:54.092723Z"},"trusted":true},"outputs":[],"source":["text_file = open(\"out.txt\", \"w\")\n","n = text_file.write(response)\n","text_file.close()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
